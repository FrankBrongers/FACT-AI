{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Towards Visually Explaining Variational Autoencoders\n",
    "To run this notebook, activate the conda environment via the environment.yml file and start jupyter notebook within this environmnent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained networks for the different models are available at:\n",
    "\n",
    "https://drive.google.com/drive/folders/1OrX5HuH6vjSD8D2gLLv7ANc1iBUuVGHY?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd Anomaly_Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n",
      "Layer is: encoder.2\n",
      "\n",
      "IPython CPU timings (estimated):\n",
      "  User   :       6.38 s.\n",
      "  System :       0.80 s.\n",
      "Wall time:       5.94 s.\n"
     ]
    }
   ],
   "source": [
    "run -t code/test_expVAE.py --dataset=mnist --model=vanilla_mnist --batch_size=32 --model_path='./ckpt/vanilla_best.pth'  --target_layer='encoder.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17-21-origin.png\n"
     ]
    }
   ],
   "source": [
    "img = random.choice([x for x in os.listdir(\"test_results/vanilla\")\n",
    "               if os.path.isfile(os.path.join(\"test_results/vanilla\", x))], )\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USCD-Ped1 Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n",
      "layer issss encoder.2\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './ckpt/vanilla_ped1_best.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Downloads/FACT/FACT-AI/Anomaly_Detection/code/test_expVAE.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test_results/{}_{}_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/FACT/FACT-AI/Anomaly_Detection/code/test_expVAE.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"layer issss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mmu_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fact-ai/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fact-ai/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fact-ai/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ckpt/vanilla_ped1_best.pth'"
     ]
    }
   ],
   "source": [
    "run code/test_expVAE.py --dataset='ucsd_ped1' --model=vanilla_ped1 --batch_size=32 --model_path='./ckpt/vanilla_ped1_best.pth' --target='encoder.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVTec Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To train the models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Info:**  training one model can take up to 1 hour on a gpu. Downloading the dataset takes up 5 Gb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the target as the index according to the following list(e.g. bottle: 0, cable: 1): \n",
    "\n",
    "['bottle', 'cable', 'capsule', 'carpet', 'grid',\n",
    "               'hazelnut', 'leather', 'metal_nut', 'pill', 'screw',\n",
    "               'tile', 'toothbrush', 'transistor', 'wood', 'zipper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_class = 5 # 5 is nut\n",
    "pre_trained_model= './ckpt/resnet18_3_mvtecClass_'+str(object_class) +'_final.pth'\n",
    "self_trained_model = './ckpt/resnet18_3_mvtecClass_'+str(object_class) +'_checkpoint.pth'\n",
    "target_layer = 'encoder.layer2.1.conv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n",
      "For class hazelnut\n",
      "Epoch [1/512] loss: 131240.692 \n",
      "Lr: 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Downloads/FACT/FACT-AI/Anomaly_Detection/code/train_expVAE.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/FACT/FACT-AI/Anomaly_Detection/code/train_expVAE.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mis_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_train_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mbest_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_train_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         save_checkpoint({\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;34m'best_train_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbest_train_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/FACT/FACT-AI/Anomaly_Detection/code/train_expVAE.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(state, is_best, outdir, args)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mcheckpoint_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{state['model']}_checkpoint.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mbest_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{state['model']}_best.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_best\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fact-ai/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fact-ai/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;31m# Copy to a buffer, then serialize that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m             \u001b[0mbuf_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPython CPU timings (estimated):\n",
      "  User   :      32.49 s.\n",
      "  System :       0.43 s.\n",
      "Wall time:      33.28 s.\n"
     ]
    }
   ],
   "source": [
    "run -t  code/train_expVAE.py --dataset=mvtec_ad --model=resnet18_3 --batch_size=8 --one_class=$object_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To test the self-trained model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Info:** to find the best IoU score set the flag: --iou True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n",
      "For class hazelnut\n",
      "Layer is: encoder.layer2.1.conv1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:222] . file not found: archive/data/93830729901536",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/Downloads/FACT/FACT-AI/Anomaly_Detection/code/test_expVAE.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test_results/{}_{}_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/FACT/FACT-AI/Anomaly_Detection/code/test_expVAE.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mmu_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fact-ai/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fact-ai/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    851\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fact-ai/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fact-ai/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:222] . file not found: archive/data/93830729901536"
     ]
    }
   ],
   "source": [
    "run code/test_expVAE.py --dataset=mvtec_ad --model=resnet18_3 --batch_size=2 --model_path=$self_trained_model --one_class=$object_class --target_layer=$target_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To load pretrained models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n",
      "For class hazelnut\n",
      "Layer is: encoder.layer2.1.conv1\n",
      "AUROC score: 0.9299496451959681\n",
      "\n",
      "IPython CPU timings (estimated):\n",
      "  User   :      41.81 s.\n",
      "  System :       0.71 s.\n",
      "Wall time:      32.31 s.\n"
     ]
    }
   ],
   "source": [
    "run -t code/test_expVAE.py --dataset=mvtec_ad --model=resnet18_3 --batch_size=2 --model_path=$pre_trained_model --one_class=$object_class --target_layer=$target_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dSprites Latent Space Disentanglement\n",
    "Make sure you are in the Latent_Space_Disentanglement directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../Latent_Space_Disentanglement/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have not yet downloaded the dSprites dataset, uncomment the following cell and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sh scripts/prepare_data.sh dsprites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing attention maps\n",
    "First we reproduce the attention maps of the two highest response latent dimensions for the baseline FactorVAE and the best performing AD-FactorVAE using $\\lambda=40$ and the first convolutional layer. Press any key to close the image. (Using the --help flag you can find more options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded checkpoint 'checkpoints/FactorVAE'\r\n"
     ]
    }
   ],
   "source": [
    "!python visualizer.py --name FactorVAE --target_layer 0 --cuda --sample_count 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded checkpoint 'checkpoints/AD-FactorVAE'\r\n"
     ]
    }
   ],
   "source": [
    "!python visualizer.py --name AD-FactorVAE --target_layer 0 --cuda --sample_count 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results\n",
    "Next we plot the results for all the models used, corresponding to 3a in the report. Using the --help flag you can find more options, for example --all_plots will show more information about the loss progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAApnElEQVR4nO3de7yVc/r/8dfVic7HkXQUSTlFJ6l0QFOUKCEZJMJkmMhQo4xyPg4zSEaTQ4pSKvo6JaWJEemAiqakE/06KCkdr98f97231W6v3b332muvver9fDzWY6/7cx/WtfZtu7o/n/u+PubuiIiI5FWRVAcgIiLpTYlEREQSokQiIiIJUSIREZGEKJGIiEhClEhERCQhSUskZjbSzNaZ2Zdx1puZPWlmS81sgZmdFrOuo5ktCdfdkawYRUQkccm8IhkFdMxhfSegXvjqCzwDYGZFgafC9Q2BnmbWMIlxiohIApKWSNx9JrAxh026Ai964BOggplVA5oBS919mbvvBMaG24qISCFULIWfXR1YGbO8KmzLrr15vIOYWV+CKxpKly7duF79+vkfqSRdETP2qspC2tL5S1/z5s5d7+6/S+QYqUwklk2b59CeLXcfAYwAOLVxYx/8ypv5E50UqHa1KzN9xYZUhyF5pPOXvroff9SKRI+RykSyCqgZs1wDWAOUiNMuIiKFUCpv/50MXBHevXU6sNnd1wJzgHpmdrSZlQAuDbcVEZFCKGlXJGY2BmgLVDGzVcBdQHEAdx8OTAXOBZYC24De4brdZnYj8A5QFBjp7l8lK04REUlM0hKJu/c8wHoH+sVZN5Ug0YhIGimydw9H7P6Zw3xPqkORLHZYUdYVK8veIkXz/dipHCMRkYPMEbt/5qgqFSlXoSJm2d03I6ng7mzZtAk2bOKHEhXy/fgqkSIi+eYw36MkUgiZGeUqVkzalaISiYjkKyWRwimZ50WJREREEqJEIiIp993yZfl2rCqlS3Jm86aZr+9XfJer/d+aPInFixblap9ZM2fQoc2Z+7Tt3r2b+rVr8sPatQDccestnFD3aPbu3Zu5zSsvvUi9mtX3iTe3n10YKJGISEo9/shDnNawAY8/8lC+HK9kyZLM/O+czFet2nVytf/UKVNYksv/mTc7vQVrVq/eJ2l9+ME0GjRsyJHVqrF3717emjyZo2rUYPasj/bZ98LuF+0T7/ENGuTqswsDJRIRSZnHH3mIR/5xH/SBR/5xX74lk1hbt27lgk6/p22L5rRschpTp/z2fPPY0S/TqmljWjdrwvVX9+a/H3/M/731JncNuoMzmzdl+bL/sXD+fM45szWtmjbmDxf34KdNmwDo0uEchg0ZTOdzzmbE00/RtVs3Jo4bn3nsiePG0e3iSwD4aMaHNDihIVf37cvrr72a798x1XT7r4ikREYS2d5rO5SH7b22B0kF6D/gL3k+7vbt2zmzeVMAateuw79fGcOLr46jXLlybFi/ng5tWtOpcxcWL1rEYw8+wP998CGVq1Rh08aNVKxUiU7ndaZDp3Pp2q0bAK2aNubBxx6nZeszuW/o3Tx47z3c/8ijAGze/BNvvvc+AHM/+4z+N/6RmwcMYMeOHbz3ztvc+9DDALz+2mt0v/gSOnXuwj1DhrBr1y6KFy8OwMTXx/PJx7Mz43/nw5mULFkyz98/FZRIRKTAZU0iQL4lk4yurQy7du3iniGDmf2fWRQpUoS1a9aw7scf+ejD6Zx/YTcqV6kCQMVKlfY71pbNm9n802Zatg7GP3pefjm9e12Wuf7Ci3pkvj+tSRN+2bqVb79ZwjeLF9OkWTMqVKzIzp07ef/tIKmULVuWxk2bMv399+jQ6dzgGN0v4qG/P5Gn71pYKJGISIH6bvkyhg0eDH34LYlkKA/bu2xn2ODBXNj9IuocXTfhzxs3dgzr169n+uxPKF68OKfUP44dO37F3RO+JbZUqdL7LF/Y42ImjBvHN4sX071H0K017d132LJlM62aNAZg+/ZtlCxVKjORHAw0RiIiBarO0XUZPGwYJaeUhM1ZVm6GklNKMnjYsHxJIhBcVfzud7+jePHifDTjQ1Z+H1RNP7Nde954fTwbNwTl7zdtDObhK1OmDFu3/gxAufLlqVCxAh/PmgXAq6+8whmtWsf9rO4XX8K4Ma/w0YwP6di5MxB0az3x9HDmL/mG+Uu+4YtFS5g+7X22bduWL9+vMFAiEZEC13/AXxjwp0GUHB2TTDZDydElGfCnQQmNkWTV49KefDF3Lu1btmDc2LFkTH7XoGFDbrn9Djp3OJvWzZpw5+3BZ17Y42L+8fhjtDm9GcuX/Y+nn3ueIYMG0qppY76cP5+/DPpr3M86vkEDSpYqRes2bSldujTbtm3jg/ff45xOnTK3KV26NKe3OIO333oLCMZIYm///e/HH+fbdy8o5gfRrGaa2Cp9aWKk9JZx/mrv2EDd446LvF/mWEmX7ZSckv9JRPa17JtvWHFY5X3auh9/1Ofu3iSR42qMRERSJiNpDBs8mAHDlETSlRKJiKRU/wF/ybeBdUkNjZGISMopiaQ3JRIREUmIEomIiCREiURERBKiRCIiB503J02iUsnD+GbJYgC+X/EdR1UsT5vTm9G80cmc3aolY15+Ke7+XTqcQ7OTT8x8tmPShAm5+vyF8+fz3tv/l6t9fvnlF46pXo0tm/d9SvPyHhcxcfz4bL8X/PbdYp9FGTv65Vx9dqJ015aIHHRef+1VTj+jJRPGjeOOOwcDUKduXWZ88ikQlGm54tJL2Lt3L72uuDLbYzz77xc4tXHjPH3+wgXzmff555zTsdOBNw4ddthhtDvrbN6aMpmel/8BCJ7K/+Tj2Yx44cW43yvju8XWFytouiIRkZR5fewYWh5XjyqlDqflcfV4feyYhI+5detWPv34Y54cPpyJ417Ldps6R9flngcfYsTTT0U+7q033Uj7li1ocVoj7h82NLN97mef8fu2bWjdrAlnt2rJls2buX/o0Mwn1ieMG8emjRu5vMdFtGramHPObM1XCxcC8MA9w/hzvxvo1vlcbuhzNd0vvpgJMTG/OXkSZ53TgVKlSkX6XqmiKxIRSYnXx47h3n5/ZOS2bbQCZq38nqv7/RGA7pf2zPNxp06ZTPsOHTi23nFUqFiJ+V98QcVKFffb7pRGp/LtkiVxj3Nd7ys5PCzn/sbUt7nzb0OpWKkSe/bs4YJOHflq4ULq1a9Pnz/04vmXRnNakyZs2bKFUqVKMXDIEOZ9/nlmVd/b+/+Zkxo14uVx45n54XRuuObqzCuI+V98wdRp0ylZsiQ7d+7k5j/ewMYNG6hUuTITxr1G3xv+GPd7nXLqqQB8t2xZZul8gAcffZwWrVrl+XeYW7oiEZGUeGzIEEZu20Y7oDjQDhi5bRuPDRmS0HFff+1VuvUIyrt369Ej7kRSByoP9ey/X8ictbBS5cq88fp42rZoTpvTm7F40dcsXrSIpd98Q9Ujq3Fak6DCSLly5ShWbP9/n3/y8WwuuSwoP39m23Zs3LAxcyyk43mdM+cfKVGiBB3P68zkiRPYsH49Xy5YQLuzzzng98ro2sp4FWQSAV2RiEiKLFm1kqz/u2sVtufVxg0b+OjDD1n01deYGXv27MHM6HPddfttu2D+PI47/ngAunc5j/+3bh2NTmvMk88M32/bFd8t559/f5xps2ZToWJF+l17Ta5K0WebtML9SpUqtU9z94sv5tEHHsDd6dS5M8WLF4/7ve6+7/4ov5ak0xWJiKRE/Ro1mZWlbVbYnleTJ07gkl69WPDNt8xf8g1fLv0ftevUYc2q1fts9/2K7xgy8A6uDbuNXp/yFjP/OyfbJALw85afKVW6NOXKl2fdjz/y/rvvAFCvfn1+WLuGuZ99Fmz388/s3r2bMmXKsnXr1sz9z2jZinFjxwbfceYMKlepTLly5bL9rNZt2vK/pUv517PD6R5O1Rvve33yn//k+XeVn5RIRCQlbhk6lKtLlWI6sAuYDlxdqhS3DB16gD3je/211zjv/K77tHW54AIee/hBvlu2LPP236t79eLaG/4Y946trE48+WROPqURLU5rxJ+u70vz01sAQVfU8y+N5vZb+tO6WRO6nXcuv/76K63btGHJokWZg+233zmYeXM/p1XTxtx95508/dzzcT+rSJEidLngAjZt2Jg590m87zX+tSA5ZYyRZLyefeqfkX9n+UFl5KVQUBn59JbXMvKvjx3DY0OGsGTVSurXqMktQ4cmNNAuOVMZeRE56HS/tKcSx0FAXVsiIpIQJRIRyVcHU3f5wSSZ50WJRETyzQ4rypZNm5RMChl3Z8umTeywokk5vsZIRCTfrCtWFjZsYsP69akORbLYYUWD85MESiQikm/2FinKDyUqpDoMKWDq2hIRkYQkNZGYWUczW2JmS83sjmzWVzSziWa2wMw+NbMTY9Z9Z2YLzWyemX2WzDhFRCTvkta1ZWZFgaeAc4BVwBwzm+zuX8dsNgiY5+4Xmtnx4fZnxaxv5+7qbBURKcSSeUXSDFjq7svcfScwFuiaZZuGwDQAd18M1DGzqkmMSURE8lkyB9urA7FlPFcBzbNsMx/oBswys2ZAbaAG8CPgwLtm5sCz7j4iuw8xs75AX4BatWrRrnbl7DaTQq5siWI6d2lM5+/QlsxEkl1t5aw3lz8APGFm84CFwBfA7nBdS3dfY2ZHAO+Z2WJ3n7nfAYMEMwKCWluq15SeVGsrven8HdqSmUhWAbH1oGsAa2I3cPctQG8AC4r6Lw9fuPua8Oc6M5tI0FW2XyIREZHUSuYYyRygnpkdbWYlgEuBybEbmFmFcB3ANcBMd99iZqXNrGy4TWmgA/BlEmMVEZE8StoVibvvNrMbgXeAosBId//KzK4P1w8HGgAvmtke4GugT7h7VWBiOPNYMeAVd387WbGKiEjeJfXJdnefCkzN0jY85v3HQL1s9lsGnJLM2EREJH/oyXYREUnIAROJmZ2eMV4RLpc1s6y38YqIyCEqyhXJM8DWmOVfwjYREZFIicQ8ZnIBd9+LqgaLiEgoSiJZZmY3mVnx8HUzsCzZgYmISHqIkkiuB84AVvNbmZO+yQxKRETSxwG7qNx9HcHDhCIiIvuJm0jM7C/u/pCZ/YP9a2Th7jclNTIREUkLOV2RLAp/alIpERGJK24icfcp4eRUJ7r7bQUYk4iIpJEcB9vdfQ/QuIBiERGRNBTleZAvzGwyMI7gYUQA3H1C0qISEZG0ESWRVAI2AO1j2hxQIhERkUiJ5F/u/p/YBjNrmaR4REQkzUR5IPEfEdtEROQQlNNzJC0Inmj/nZndErOqHMFEVSIiIjl2bZUAyoTblI1p3wJclMygREQkfeT0HMkMYIaZjXL3FWZW2t1/ibe9iIgcmqKMkRxlZl8TPuluZqeY2dPJDUtERNJFlETyd+D3BLcA4+7zgTOTGJOIiKSRSHO2u/vKLE17khCLiIikoSjPkaw0szMAN7MSwE38VtBRREQOcVEntuoHVCeY2KpRuCwiIhJpYqv1QK8CiEVERNLQAROJmR0N/AmoE7u9u5+fvLBERCRdRBkjeQN4HpgC7E1qNCIiknaiJJJf3f3JpEciIiJpKUoiecLM7gLeBXZkNLr73KRFJSIiaSNKIjkJ+APBfCQZXVvOvvOTiIjIISpKIrkQqOvuO5MdjIiIpJ8oz5HMByokOQ4REUlTUa5IqgKLzWwO+46R6PZfERGJlEjuSnoUIiKStqI82T6jIAIREZH0FKn6b16ZWUczW2JmS83sjmzWVzSziWa2wMw+NbMTo+4rIiKFQ9ISiZkVBZ4COgENgZ5m1jDLZoOAee5+MnAF8EQu9hURkULggInEzG6O0paNZsBSd18W3jo8FuiaZZuGwDQAd18M1DGzqhH3FRGRQiDKYPuVhFcKMa7Kpi2r6kDshFirgOZZtpkPdANmmVkzoDZQI+K+AJhZX6AvQK1atWhXu/IBwpLCqGyJYjp3aUzn79AWN5GYWU/gMuBoM5scs6os4bS7B2DZtHmW5QcISrDMAxYCXwC7I+4bNLqPAEYAnNq4sU9fESU0KWza1a6Mzl360vk7tOV0RTIbWAtUAR6Naf8ZWBDh2KuAmjHLNYA1sRu4+xagN4CZGbA8fJU60L4iIlI4xE0k7r4CWAG0yOOx5wD1wvlMVgOXElzhZDKzCsC2cBzkGmCmu28JH37McV8RESkcokxs1Q14EDiCoMvJAHf3cjnt5+67zexG4B2gKDDS3b8ys+vD9cOBBsCLZrYH+Brok9O+efyOIiKSRFEG2x8Curj7otwe3N2nAlOztA2Pef8xUC/qviIiUvhEeY7kx7wkEREROTREuSL5zMxeJZhyN7Zo44RkBSUiIukjSiIpB2wDOsS0OaBEIiIikYo29i6IQEREJD1FKZFynJlNM7Mvw+WTzezO5IcmIiLpIMpg+3PAQGAXgLsvIHiuQ0REJFIiKeXun2Zp252MYEREJP1ESSTrzewYwlpXZnYRQekUERGRSHdt9SMoini8ma0mqIV1eVKjEhGRtBHlrq1lwNlmVhoo4u4/Jz8sERFJF1FqbVUgmL2wDlAsKNIL7n5TMgMTEZH0EKVrayrwCcF8IXuTG46IiKSbKInkcHe/JemRiIhIWopy19ZLZnatmVUzs0oZr6RHJiIiaSHKFclO4GHgr/w23a0DdZMVlIiIpI8oieQW4Fh3X5/sYEREJP1E6dr6iqD6r4iIyH6iXJHsAeaZ2XT2nY9Et/+KiEikRPJG+BIREdlPlCfbXzCzkkAtd19SADGJiEgaiTIfSRdgHvB2uNzIzCYnOS4REUkTUQbb/wY0A34CcPd5wNFJi0hERNJKlESy2903Z2nzbLcUEZFDTpTB9i/N7DKgqJnVA24CZic3LBERSRdRrkj+BJxAcOvvGGAL8OckxiQiImnkgInE3be5+1/dvam7Nwnf/1oQwUn+WrFkEde1b8rbY17Yb92ePXsYcOE53HfdFZltX3w0nT91bEW/DmcwYcQ/CjJUEUkjcbu2zGwKOYyFuPv5SYlIkqZ2/Qbc8ugzjHrgbjr2vHKfdW+9+C+q163H9q1bgSCxPDd0EENGjqVy1Wrc3uNcmrb/PTWPPS4VoYtIIZbTGMkjBRaFFJjylauwcum+jwNt+GENc2dMo/v1NzHl3yMAWLrgC46sVYcja9YGoNW5XZkz7R0lEhHZT9xE4u4zCjIQKRgvP3ofu3buZN3qVRxRvQYAI++7iz8MuJPtv2zN3G7jjz9QpdpRmcuVjqzGt/PnFni8IlL4RXkgcaGZLcjy+sjMHjezygURpOSPLz6azq/bt9G47VmZVyWfTX+P8pWrcMyJJ++zrWfTq5kxzbKISKwot//+H0HhxlfC5UsBAzYDo4AuSYlM8tXOHb/y4sP3MPDpUXwwYSwrv11M4zZnsXjuHOZ88C5zZ0xj184dbNv6M0/cdiMdL7uK9WvXZO6/8Ye1VDriyBR+AxEprKIkkpbu3jJmeaGZ/cfdW5rZ5ckKTPLX+GeeoG3XiziiRk1qH9eAOdPfBeDyWwdx+a2DAPjyv7OZPHI4Nz/8T/bs3s3aFcv5cdX3VDriSGZNncSfH3kqlV9BRAqpKM+RlDGz5hkLZtYMKBMu7k5KVJJnH02ZwID2TenRoDoD2jfloykTWL1sKQtmz6TzldcCUOu44/n+28U5HqdosWJcM/hehvW5jJvPa8MZnbpQq179gvgKIpJmzD3naidm1hQYSZA8jOCBxGsIJrw6z91fS3aQUZ3auLEPfuXNVIeRMh9NmcCEwbcx6tfttAJmAVcdXpJuwx6mdZduqQ4vR+1qV2b6ig2pDkPySOcvfXU//qjP3b1JIseI8kDiHHc/CWgENHL3k939U3f/pTAlEYFJj9/PqF+30w4oDrQDRv26nUmP35/iyETkYHbAMRIzOwzoDtQBimXcuePuQyPs2xF4AigK/MvdH8iyvjzwMlArjOURd/93uO474GeCgf7diWbMQ8GKtWtolaWtVdguIpIsUcZIJgFdCcZDfol55cjMigJPAZ2AhkBPM2uYZbN+wNfufgrQFnjUzErErG/n7o2URKKpXe0oZmVpmxW2i4gkS5S7tmq4e8c8HLsZsNTdlwGY2ViChPR1zDYOlLXgMqcMsBEN4OdZ1/4DuSq7MZL+A1MdmogcxKIkktlmdpK7L8zlsasDK2OWVwHNs2zzT2AysAYoC1zi7nvDdQ68a2YOPOvuI7L7EDPrC/QFqFWrFu1qH7rPSLa78VpOqFKGfkOGsGTVSurXqMngoUPpfmnPVId2QGVLFDukz1260/k7tEVJJK2Aq8xsOUEpeQPc3U/OeTeyeww66y1ivyeYxrc9cAzwnpl95O5bCJ5fWWNmR4Tti9195n4HDBLMCAju2jrU7xyp1KID97zXYZ+2Ue/O4r4bruDCa2/MLNa4fu1qnrz9Zn5avw4rUoRzLr6czldcAwRPwI+8dzB79+7lrIt60q3vn5Iet+76SW86f4e2KGMknYB6QAeCp9g7E+1p9lVAzZjlGgRXHrF6AxM8sBRYDhwP4O5rwp/rgIkEXWWSBxlVf2e8MT6zrWjRYlx1+xCenDqTB8a+ydujR7Fy6TeZVX//+txo/v7mh8x6axIrl36TwuhFpLCLcvvvCndfAWwnuKLIeB3IHKCemR0dDqBfStCNFet74CwAM6sK1AeWmVlpMysbtpcmSGJfRvtKkp2sVX8rHlGVuicEF5Uly5ShxjHHsvHHtftU/S1eokRm1V8RkXiiFG0838y+JbhamAF8R1B/K0fuvhu4EXgHWAS85u5fmdn1ZnZ9uNkw4AwzWwhMA2539/VAVWCWmc0HPgXecve3c/3tJFNs1d+s1q1ayfJFX1LvlNOyrfq74ce1BRmqiKSZKGMkw4DTgffd/VQzawdEGr1196nA1Cxtw2PeryG42si63zLglCifIQeWtepvRvl4gO2//MLDN11D74FDKVWmrKr+ikiuRRkj2eXuG4AiZlbE3acTPOUuaSCj6m/fIfdTq97xrIypsbV71y4evukaWnfpxukdzgWgctVqqvorIrkSJZH8ZGZlgJnAaDN7Aj3rUahkV6gxQ9aqv99/G4yTuDtP33krNY6px/m9r8vc/tiTGmVW/d21cyezpk6iSfv9LhpFRDJF6drqSjDQ3h/oBZQH7k5mUBLdfoUa16zmqsG3AVD3hJNZMHsm974yCQiq/r4+4kkAFs/9lBmTxlPruAbcesHZAFzWfyCN25yVWfV37949tO9+qar+ikiOolT/fdDdbz9QW2FwKFb/HdC+Kc+vWU27mLbpQJ+jqvPIB3NSFVau6TmE9Kbzl74KpPovcE42bZ0S+VDJPyrUKCKpFjeRmNkN4W259bPM174cWFBwIUpOVKhRRFItpyuSVwieYJ8c/sx4NXZ3TbFbSHTtP5CrDi/JdGAXQbfWVYeXpKsKNYpIAYk72O7um4HNBOXfixI8JFiMYOrdMu7+fQHFKDnImPmwz+P3s2LtGmpXO4pu/QcW+hkRReTgEWViqxuBvwE/ArGVeQ9UtFEKSOsu3QpF4lixZNF+xSEBnhrUn88+fJ/ylavw9ynTM9t7nXYso+cuzfZYe/bs4faLOlLpiGoMevbFpMcuInkXZbD9z0B9dz/B3U8KX0oisp/sikMCtL3wEgY/NzpXx3rrxX9RvW69/AxPRJIkSiJZSdDFJXJAWYtDApzQ9HTKlK8Y+RgbfljD3BnTOLvHZfkdnogkQZREsgz40MwGmtktGa9kBybJtWLJIq5r35S3x7ywT/tTg/rT+4yT+HOXdnH2zFlOxSGjGnnfXfxhwJ2YRfnPU0RSLcpf6vfAe0AJglkMM16SxvKzGypD1uKQefHZ9PcoX7kKx5yo3lORdHHAwXZ3vxuCeUHc/ZfkhyQFJV431LpVK+PsEV9GcciBT4/igwljWfntYhq3OSvXx1k8dw5zPniXuTOmsWvnDrZt/ZknbruRmx/+Z66PJSIFI8p8JC3M7GuCOUUws1PM7OmkRyZJlx/dUBniFYfMrctvHcRzMz5n+Aef0v/RZzipeSslEZFCLkrX1t8J5lbfAODu84EzkxiTFIC8dEPFqzK8etlSFsyeSecrrwWC4pDfx5Srf+yWGxjYswtrlv+Pa9s05v3xrwCwY/t2rm3TmGvbNOaEY+oy+d/P5vO3FJGCEKX6L+6+MsvkRnuSE44UhLx0Q+VUZbh1l2488NpbmdtWr3ssj0x4N3P5lseeyfaY4xetznyfXdG/E5ufwYnNz8jt1xORAhbp9l8zOwNwMythZgMIu7mkcIt3BZGXbqhJj9/PqF+30w4oDrQDRv26nUmP35/U7yAihV+URHI90A+oDqwimB2xXxJjknyQcQXx/JrV/OrO82tWM2HwbUx6/pk8dUOpyrCIxBPlrq31BBNaSRqJvYKA364g+oweuc88JVG7oWpXO4pZWeY9UZVhEYFod209ZGblzKy4mU0zs/Vmpuq/hVx+X0GoyrCIxBOla6uDu28BOhN0bR0H3JbUqCRh+T1PSesu3eg27GH6HFWdw83oc1R1ug17uFAUixSR1Ipy11bx8Oe5wBh335jlDi4phLr2H8hVsXdZEVxBdEvgCqKwVBkWkcIlSiKZYmaLge3AH83sd8CvyQ1LEqV5SkSkoEQZbL/DzB4Etrj7HjP7Beia/NAkUbqCEJGCEDeRmFl7d//AzLrFtMVuMiGZgYmISHrI6YqkDfABwTztWTlKJCIiQs5ztt8V/uxdcOGIiEi6yalrK8fJq9z9sfwPR1Lph5UrOLJm7VSHISJpJqfnSDImsGoC3EBQIqU6QcmUhskPTQrShOeepN85LZjw3JOpDkVE0kxOXVsZE1q9C5zm7j+Hy38DxhVIdFIgJjz3JONefAL6EPwEul17U4qjEpF0EeU5klrAzpjlnUCdpEQjBS4jiey8fDuUh52Xb1cyEZFciZJIXgI+NbOJBHdrXQi8kNSopEBkTSKAkomI5NoBa225+71Ab2AT8BPQ2901CUWa+2HlCkY/+gA7z49JIhnKw87ztzP60Qf4YeWKlMQnIukjStFG3H2uuz8Rvr6IenAz62hmS8xsqZndkc368mY2xczmm9lXZtY76r6SmCNr1qbXrXdQYnJJ2Jxl5WYoMbkkvW69Q3dxicgBRUokeWFmRYGngE4Ed3n1NLOsd3v1A75291OAtsCj4SyMUfaVBHW79iZ6XHEzJV6OSSabocTLJelxxc3q1hKRSJKWSIBmwFJ3X+buO4Gx7F+jy4GyFtReKQNsBHZH3FfywT7JZKWSiIjkXpTB9ryqDqyMWV4FNM+yzT+BycAagmdWLnH3vWYWZV8AzKwv0BegVq1atKtdOX+iP4S0u+du6lYozbDBg7l92CD6D/hLgcdQtkQxnbs0pvN3aEtmIslu0hLPsvx7YB7QHjgGeM/MPoq4b9DoPgIYAXBq48Y+fcWGvMZ7SGvUow9PnX42R9asTSp+h+1qV07J50r+0Pk7tCWza2sVUDNmuQbBlUes3sAEDywFlgPHR9xX8pkG1kUkL5KZSOYA9czsaDMrAVxK0I0V63vgLAAzqwrUB5ZF3FdERAqBpHVtuftuM7sReAcoCox096/M7Ppw/XBgGDDKzBYSdGfd7u7rAbLbN1mxiohI3iVzjAR3nwpMzdI2POb9GqBD1H1FRKTwSWbXloiIHAKUSEREJCFKJCIikhAlEhERSYgSiYiIJESJREREEqJEIiIiCVEiERGRhCiRiIhIQpRIREQkIUokIiKSECUSERFJiBKJiIgkRIlEREQSokQiIiIJUSIREZGEKJGIiEhClEhERCQhSiQiIpIQJRIREUmIEomIiCREiURERBKiRCIiIglRIhERkYQokYiISEKUSEREJCFKJCIikhAlEhERSYgSiYiIJESJREREEqJEIiIiCVEiERGRhCiRiIhIQpRIREQkIUokIiKSkKQmEjPraGZLzGypmd2RzfrbzGxe+PrSzPaYWaVw3XdmtjBc91ky4xQRkbwrlqwDm1lR4CngHGAVMMfMJrv71xnbuPvDwMPh9l2A/u6+MeYw7dx9fbJiFBGRxCXziqQZsNTdl7n7TmAs0DWH7XsCY5IYj4iIJEHSrkiA6sDKmOVVQPPsNjSzUkBH4MaYZgfeNTMHnnX3EXH27Qv0DRd3dD/+qC8TDVxSogqgq8/0pfOXvuoneoBkJhLLps3jbNsF+E+Wbq2W7r7GzI4A3jOzxe4+c78DBglmBICZfebuTRINXAqezl160/lLX/kxBp3Mrq1VQM2Y5RrAmjjbXkqWbi13XxP+XAdMJOgqExGRQiaZiWQOUM/MjjazEgTJYnLWjcysPNAGmBTTVtrMyma8BzoA6rISESmEkta15e67zexG4B2gKDDS3b8ys+vD9cPDTS8E3nX3X2J2rwpMNLOMGF9x97cjfGy24yiSFnTu0pvOX/pK+NyZe7xhCxERkQPTk+0iIpIQJRIREUnIQZFIDlSKRQqf7ErgmFklM3vPzL4Nf1ZMdZwCZjbSzNaZ2ZcxbXHPlZkNDP8Wl5jZ71MTtWSIc/7+ZmarY0pUnRuzLtfnL+0TSUwplk5AQ6CnmTVMbVQSUTt3bxTz/MEdwDR3rwdMC5cl9UYRPDAcK9tzFf7tXQqcEO7zdPg3Kqkziv3PH8Dj4d9fI3efCnk/f2mfSMh9KRYpvLoCL4TvXwAuSF0okiF8EHhjluZ456orMNbdd7j7cmApegYspeKcv3jydP4OhkSSXSmW6imKRaLLKIHzeVjmBqCqu68FCH8ekbLo5EDinSv9PaaPG81sQdj1ldE1mafzdzAkktyUYpHCo6W7n0bQJdnPzM5MdUCSL/T3mB6eAY4BGgFrgUfD9jydv4MhkeSmFIsUEnFK4PxoZtUAwp/rUhehHEC8c6W/xzTg7j+6+x533ws8x2/dV3k6fwdDIolUikUKjxxK4EwGrgw3u5KYsjlS6MQ7V5OBS83sMDM7GqgHfJqC+CQHGf8ICF3IbyWo8nT+kln9t0DEK8WS4rAkZ9mWwDGzOcBrZtYH+B7okcIYJWRmY4C2QBUzWwXcBTxANucqLIP0GvA1sBvo5+57UhK4AHHPX1sza0TQbfUdcB3k/fypRIqIiCTkYOjaEhGRFFIiERGRhCiRiIhIQpRIREQkIUokIiKSECUSkVwws0H5fLzZ+Xk8kVTQ7b+Sdix4AMXCp3IL+rO3unuZwhRTVGZWzN13x1uOup9IVroikbRgZnXMbJGZPQ3MBWqa2W1mNicsPHd3zLZXhG3zzeylsK22mU0L26eZWa2wfZSZPWlms81smZldFLZXM7OZ4VwNX5pZazN7ACgZto2OE9PWmDguMrNR4fuqZjYxjGm+mZ0Rtm8Nf5qZPRx+1kIzuyRsb2tmH5rZeDNbHH7ufvWQzOwYM3s7LIL5kZkdH/P9HjOz6cCD2Sw3MrNPwt/LxIzifeFn3mdmM4Cb8/VkysHH3fXSq9C/gDrAXuD0cLkDMIKgyFwR4E3gTIJ5FJYAVcLtKoU/pwBXhu+vBt4I348CxoXHaEgwJQHArcBfw/dFgbLh+63xYspm/UXAqPD9q8CfY45XPnZ7oDvwXriuKsHT4tUInkjeTFDzqAjwMdAqm9/PNKBe+L458EHM93sTKBpneQHQJnw/FPh7+P5D4OlUn3e90uOV9iVS5JCywt0/Cd93CF9fhMtlCOoCnQKMd/f1AO6eMQ9DC6Bb+P4l4KGY477hQZfU12ZWNWybA4w0s+Lh+nkRYspJe+CKMKY9BMkhVitgTLjux/BKoCmwBfjU3VcBmNk8ggQ2K2NHMysDnAGMi7lYOSzm2ON83zIX49x9j5mVByq4+4yw/QWCpJrh1QjfS0RdW5JWfol5b8D9/tsMb8e6+/Nhe5SBv9htdmQ5Lh5MBnQmsBp4ycyuiBBT1uMeHiGOfT43jtj49rB/jbwiwE8xv4tG7t4ghxizLscTdTs5xCmRSLp6B7g6/Nc4ZlbdzI4g6OK52Mwqh+2Vwu1nE1SGBuhFzL/os2NmtYF17v4c8DxwWrhqV3iVEs+PZtbAzIoQVFXNMA24ITx2UTMrl2W/mcAl4brfESSxSFVz3X0LsNzMeoTHNzM7JcJ+m4FNZtY6bPoDMCOHXUSypUQiacnd3wVeAT42s4XAeIJxjK+Ae4EZZjYfeCzc5Sagt5ktIPgf5oEGkNsC88zsC4LxiyfC9hHAAjMbHWe/OwjGID4gmDAow81AuzDWzwnGcmJNJBivmB/u+xd3/+EAMcbqBfQJv/NXRJ9u+krg4fD30ohgnEQkV3T7r4iIJERXJCIikhAlEhERSYgSiYiIJESJREREEqJEIiIiCVEiERGRhCiRiIhIQv4/7SfeEndVM5kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run plotter.py --names 'gamma40 lambda1_gamma40 lambda20_gamma40 lambda40_gamma40 conv3_lambda1_gamma40'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
